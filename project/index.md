---
layout: post
title: projects & publications
---
### <a href="{{ site.github.url }}/articles/16/essence-machine-deep-learning">Essence of Machine Learning (and Deep Learning)</a>

"Base" course for new members at DSLab-HUST. Pre-requisite for subsequent training sessions in *Topic models* (or *Probabilistic Graphical Models*) and *Deep Learning*. 

**Motivation.** The majority of DSLab-HUST members, including myself back in early 2016, are aspiring ML ***self-learners***, and have been struggling (*a lot*) to study **probabilistic/Bayesian modelling** on our own. For the newcomers - who are very likely exposed to Deep Neural Networks (DNN) *before* probabilistic modelling - I found it considerably more challenging and time-consuming to see the [big picture of Machine Learning](/articles/16/essence-machine-deep-learning#map) (*Deep Learning* included) research without *proper background in probabilistic (graphical) models - PGM* (which I wish I had known earlier).

Nevertheless, it's truly hard to find a beginner-level MOOC in PGM{% sidenote 'sn-id-mooc' "Prof. [Daphne Koller's course in PGM](https://www.coursera.org/specializations/probabilistic-graphical-models) is a little bit abstract, and not a beginner-level course on ML" %} which can instill (i) probabilistic/statistical reasoning, and also introduce (ii) [ML core concepts](/articles/16/essence-machine-deep-learning#core) in a intuitive flow as Prof. [Andrew Ng's course](https://www.coursera.org/learn/machine-learning) did. Therefore, this course is devised to address the 2 purposes. Upon completing this course, the learners can, hopefully, explore the spectrum of ML research with minimal guidance, keep their heads up on the big picture to not get lost in the complexity (and the hype!) of the field, later learn advanced materials more efficiently, and catch up with recent advances in Machine Learning research.
`[`[`Read more`](/articles/16/essence-machine-deep-learning)`]`



### Projects related to Recommendation Systems
To be updated.

### Fully Automated Multi-label Image Annotation by Convolutional Neural Network and Adaptive Thresholding
<p>
<u>Hoa M. Le</u>, <a href="http://soict.hust.edu.vn/en/index.php/bo-mon-trung-tam/information-system/faculty-and-staff/230-nguyen-thi-oanh-phd.html">Thi-Oanh Nguyen</a>, Dung Ngo-Tien
<br> <em>in Proceedings of the 7th International Symposium on Information and Communication Technology (SoICT 2016). DOI: 10.1145/3011077.3011118</em> 
</p>

*Abstract*. This paper presents a fully automated and flexible ConvNet-based classifier for multi-label image annotation. The classifier alleviates hierarchical representation of image from a convolutional neural network, and adaptive thresholding technique on the ranked list of label scores. The method can annotate images with arbitrary number of labels that the classifier finds fit, as opposed to common methods which only assign a fixed number of those. Experiments show state-of-the-art on classification accuracy and competitive annotation performance across 2 intrinsically different datasets, Corel5K and MSRCv2. Although the proposed method shows some limitation in learning label semantics, empirical study indicates that it was due to the established drawback of univariate loss function, which the classifier optimised, in multi-label classification. It, therefore, opens for number of directions to improve the performance, while still retains the merits of the proposed method.
`[`[`PDF`](https://1drv.ms/b/s!ApOZHae4ogqZwTBo1fsEvZ0uflbI)`]` `[`[`Code`](https://github.com/hoamle/multiLabel)`]`