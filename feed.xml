<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hoa M. Le's Personal site</title>
    <description></description>
    <link>http://hoamle.github.io/</link>
    <atom:link href="http://hoamle.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 08 Jul 2021 23:44:06 -0400</pubDate>
    <lastBuildDate>Thu, 08 Jul 2021 23:44:06 -0400</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Machine Learning as Probabilistic (Bayesian) modelling, in simpler language</title>
        <description>&lt;p&gt;&lt;label for=&quot;motivation&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;motivation&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;em&gt;Motivation&lt;/em&gt;. Many DSLab-HUST members, including myself back in late 2015, had been struggling with studying &lt;strong&gt;probabilistic (Bayesian) modelling&lt;/strong&gt; given pretty limited training we had. The issue got worse when some others, instead, explored Deep Neural Networks - DNN first, and their intersection - Deep Bayesian modelling, where the links / intuition between the 2 domains were hard to made without a &lt;em&gt;proper foundation&lt;/em&gt; in Probabilistic modelling. I reckoned that adding more training sessions to the existing ones with &lt;em&gt;revised&lt;/em&gt; ML fundamentals - to fill in probabilistic interpretation and DNN bits, &lt;em&gt;more visualization&lt;/em&gt; - to accompany the equation, and &lt;a href=&quot;//edwardlib.org/api/model&quot;&gt;&lt;em&gt;augmented graphical model notation&lt;/em&gt;&lt;/a&gt; - to include deterministic nodes in stochastic structures - might have alleviated the problem. For that this series was developed, and added to the training sessions in early 2017 - while I was a Research assistant at the lab. &lt;/span&gt;
&lt;strong&gt;“Base”&lt;/strong&gt; course for Machine Learning (ML) starters, under the language of &lt;strong&gt;&lt;em&gt;probabilistic modelling&lt;/em&gt;&lt;/strong&gt;. Pre-requisite for subsequent training sessions in Probabilistic (graphical) models e.g. Topic models, Deep Learning, and other ML topics.&lt;/p&gt;

&lt;p&gt;The objective of this course is to introduce core concepts of &lt;em&gt;modern&lt;/em&gt; Machine learning under probabilistic perspective, with (i) more visualization &amp;amp; interpretation of the accompanied math, and (ii) &lt;a href=&quot;//edwardlib.org/api/model&quot;&gt;augmented graphical model notation&lt;/a&gt; to incorporate DNN architectures into stochastic structure of Probabilistic models. Upon completing this course, the learners can, hopefully, explore the &lt;a href=&quot;/post/16/a-ml-dl-map&quot;&gt;spectrum of ML/AI research&lt;/a&gt;  with minimal guidance, keep their heads up on the big picture to not get lost in the complexity of the field, later learn advanced materials more efficiently.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-requisite&lt;/strong&gt;. Basic knowledge in the following mathematical areas&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linear Algebra: understand the notion of &lt;em&gt;vectors&lt;/em&gt; and &lt;em&gt;space&lt;/em&gt; to represent data; basic arithmetics: dot product, matrix multiplication.&lt;/li&gt;
  &lt;li&gt;Probability &amp;amp; Statistics: understand the notion of &lt;em&gt;probability distribution&lt;/em&gt; to quantitatively express “possibilities”&lt;/li&gt;
  &lt;li&gt;Calculus: can do partial derivatives, know the chain-rule (not required for “base” course if not diving deep into &lt;em&gt;how&lt;/em&gt; &lt;a href=&quot;#core&quot;&gt;learning task&lt;/a&gt; is done, but recommended for the long-term nevertheless)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;core-concepts&quot;&gt;&lt;a name=&quot;core&quot;&gt;Core concepts&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Via the lens of probabilistic modelling, we will introduce the following high-level concepts (in &lt;strong&gt;&lt;em&gt;bold italic&lt;/em&gt;&lt;/strong&gt;).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Tip: read  the side notes, tap on the numbered superscript below (if you’re on your phone) for more details.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;build-a-machine-learning-model&quot;&gt;Build a Machine Learning model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Design principle: &lt;a name=&quot;arc&quot;&gt;&lt;strong&gt;&lt;em&gt;Model&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt; &lt;label for=&quot;sn-model&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-model&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;em&gt;“Model is a simplification of reality”&lt;/em&gt;. Formulate real-life problems as &lt;strong&gt;&lt;em&gt;parametric models&lt;/em&gt;&lt;/strong&gt;. Note: &lt;em&gt;non-parametric models/methods&lt;/em&gt; are not covered and left for further reading after “base” course. See &lt;a href=&quot;#map&quot;&gt;the map&lt;/a&gt;. &lt;/span&gt; = &lt;em&gt;(model)&lt;/em&gt; &lt;strong&gt;&lt;em&gt;Structure&lt;/em&gt;&lt;/strong&gt;&lt;label for=&quot;sn-structure&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-structure&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Relationships between the elements of a model: data, parameters, and hyperparameters.  Relationships can either be &lt;em&gt;deterministic&lt;/em&gt; or &lt;em&gt;stochastic&lt;/em&gt;, and can be summarized graphically by &lt;a name=&quot;graphical&quot; href=&quot;/post/17/principle-of-modelling&quot;&gt;&lt;strong&gt;&lt;em&gt;graphical models&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;. &lt;/span&gt; + &lt;strong&gt;&lt;em&gt;Learning Framework&lt;/em&gt;&lt;/strong&gt;&lt;label for=&quot;sn-framework&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-framework&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Probabilistic framework: &lt;strong&gt;&lt;em&gt;maximum likelihood estimation&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Bayesian reasoning&lt;/em&gt;&lt;/strong&gt;. Non-probabilistic frameworks include &lt;a href=&quot;//metacademy.org/roadmaps/rgrosse/dgml&quot;&gt;&lt;em&gt;differential geometry&lt;/em&gt;&lt;/a&gt;, which is more mathematical i.e. more abstract, and is only recommended upon completing &lt;code class=&quot;highlighter-rouge&quot;&gt;PGM&lt;/code&gt; node in the &lt;a href=&quot;#plan&quot;&gt;study-plan&lt;/a&gt;. &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Note: the term “&lt;strong&gt;Architecture&lt;/strong&gt;” - often seen in DNN - can be thought of as a sub-concept of “&lt;strong&gt;Structure&lt;/strong&gt;”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Tasks to do:  &lt;strong&gt;&lt;em&gt;Learning&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;Inference&lt;/em&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;em&gt;Decision making&lt;/em&gt;&lt;/strong&gt;&lt;label for=&quot;sn-estimate&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-estimate&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Realize a model by finding/computing (point) estimates of unknown parameters/ hyper-parameters (&lt;strong&gt;&lt;em&gt;learning task&lt;/em&gt;&lt;/strong&gt;) of the model; other quantities of interest, e.g. predictive posterior distribution of outcomes/ estimates of missing data/ … given trained model (&lt;strong&gt;&lt;em&gt;inference tasks&lt;/em&gt;&lt;/strong&gt;), in order to make optimal &lt;strong&gt;&lt;em&gt;decisions&lt;/em&gt;&lt;/strong&gt; - prediction, actions - under &lt;em&gt;uncertainties&lt;/em&gt;. &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;evaluate-performance-of-a-model&quot;&gt;Evaluate performance of a model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Assessment metrics&lt;/em&gt;&lt;/strong&gt;: Which metrics to measure model performance?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Model selection&lt;/em&gt;&lt;/strong&gt;: Which model to use, or can we ensemble / average different models?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Model criticism&lt;/em&gt;&lt;/strong&gt;: Are the results meaningful&lt;label for=&quot;sn-meaningful&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-meaningful&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;in terms of &lt;em&gt;statistical&lt;/em&gt; significance, interpretability, or interesting observation &lt;/span&gt;  and legitimate&lt;label for=&quot;sn-analyze&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-analyze&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;We will touch on &lt;strong&gt;&lt;em&gt;Experimental design&lt;/em&gt;&lt;/strong&gt; &lt;/span&gt;?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;regularize-a-model&quot;&gt;Regularize a model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;To fight &lt;strong&gt;&lt;em&gt;overfitting&lt;/em&gt;&lt;/strong&gt; issue. Example approaches: weight penalty, &lt;strong&gt;&lt;em&gt;Bayesian inference/reasoning&lt;/em&gt;&lt;/strong&gt;&lt;label for=&quot;sn-bayes&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-bayes&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;We will also see Bayesian reasoning, and eventually &lt;em&gt;Bayesian inference methods&lt;/em&gt;, when building &lt;strong&gt;&lt;em&gt;generative models&lt;/em&gt;&lt;/strong&gt; for clustering problem &lt;/span&gt;, Data augmentation, Dropout, Ensemble methods&lt;/li&gt;
  &lt;li&gt;To strive for human-interpretable model via &lt;em&gt;sparsity&lt;/em&gt;&lt;label for=&quot;sn-sparse&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-sparse&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;covered in Topic Models course &lt;/span&gt; or &lt;a href=&quot;//en.wikipedia.org/wiki/Regularization*(mathematics)&quot;&gt;other objectives&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;course-notes&quot;&gt;&lt;a name=&quot;note&quot;&gt;Course notes&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Session 1 - &lt;a href=&quot;//raw.githubusercontent.com/hoamle/essence_ml/e788aef7617fed6911bcfd710ebbccd8ed34eae6/essence_ml.pdf&quot;&gt;Introduction&lt;/a&gt;  &amp;amp; &lt;a href=&quot;/post/17/primer-on-building-ml-solutions&quot;&gt;Primer on Building a Machine Learning solution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Session 2 - Principles of Modelling: Model structure (linear models), Learning framework&lt;/p&gt;

&lt;p&gt;Session 3 - Model structure (non-linear models), Regularization, Model selection&lt;/p&gt;

&lt;p&gt;Session 4 - Bayesian inference, Generative models&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;//1drv.ms/p/s!ApOZHae4ogqZgog1P9HHN_4u3UeMeA&quot;&gt;RECAP Session 2-4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Session 5 - Introduction to &lt;a href=&quot;//1drv.ms/p/s!ApOZHae4ogqZgog1P9HHN_4u3UeMeA&quot;&gt;Latent Variable Models &amp;amp; How to learn classical LVMs&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;&lt;a name=&quot;ref&quot;&gt;References&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For this course&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Andrew Ng’s Machine Learning class (&lt;a href=&quot;//www.coursera.org/learn/machine-learning&quot;&gt;Coursera&lt;/a&gt; or &lt;a href=&quot;//cs229.stanford.edu/&quot;&gt;CS229&lt;/a&gt;) &amp;lt;- Practical introduction to ML and common ML algorithms.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;//cs231n.stanford.edu/&quot;&gt;Stanford CS231n&lt;/a&gt; - ConvNet for Visual Recognition &amp;lt;- Practical course on DNN under the context of visual recognition.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;//www.cs.ubc.ca/~murphyk/MLbook/&quot;&gt;Machine Learning: a Probabilistic Perspective&lt;/a&gt; (Kevin Murphy) &amp;lt;- Comprehensive textbooks on Probabilistic modelling. Alternative: &lt;a href=&quot;//www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt; (Christopher Bishop)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For bigger, more expressive landscape of Deep Bayesian modelling&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;//videolectures.net/deeplearning2016_mohamed_generative_models/&quot;&gt;Shakir Mohamed’s talk&lt;/a&gt; on Deep Generative Models in Deep Learning Summer School, 2016 &amp;lt;- Terrific summary of modelling principles and categorization of model classes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;//twitter.com/dpkingma/status/914277278602821633?lang=en&quot;&gt;Durk Kingma’s PhD Thesis&lt;/a&gt; &amp;lt;- Self-contained references for the building blocks of the most recent advances such as Amortized inference with path-wise Stochastic-gradient VI (where VAE is a special case), Variational Dropout, Inverse Autoregressive Flow&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;course-logistics&quot;&gt;&lt;a name=&quot;study&quot;&gt;Course logistics&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;2 sessions/week: 1x “&lt;strong&gt;Lecture&lt;/strong&gt;” session + 1x optional “&lt;strong&gt;Study-group&lt;/strong&gt;” session.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Lectures&lt;/em&gt; are meant to lead you in the right direction, and that’s it — just to get you started. They are &lt;strong&gt;not&lt;/strong&gt; meant to tell you &lt;em&gt;everything&lt;/em&gt; in &lt;em&gt;every&lt;/em&gt; details. Thus, you should also utilize the reference reading materials, online resources for missing details&lt;/p&gt;

&lt;p&gt;It should also be reckoned that &lt;em&gt;we do not know everything&lt;/em&gt;. In many situations, we &lt;em&gt;don’t even know what we don’t know&lt;/em&gt;. Thus do not hesitate to get in touch with the course instructors, the teaching assistant, your classmates, circles of friends for further support/discussion/…&lt;/p&gt;
</description>
        <pubDate>Fri, 17 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://hoamle.github.io/post/17/mlpp-primer</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/17/mlpp-primer</guid>
        
        <category>tutorial</category>
        
        
      </item>
    
      <item>
        <title>Machine learning appendix</title>
        <description>&lt;p&gt;&lt;em&gt;to be updated sporadically, suggestions are highly appreciated&lt;/em&gt;
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;glossary-of-common-ml-terminologies&quot;&gt;&lt;a name=&quot;glossary&quot;&gt;Glossary of common ML terminologies&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Glossary of common terms and their &lt;em&gt;synonyms&lt;/em&gt; (or &lt;em&gt;&lt;font color=&quot;red&quot;&gt;strongly related&lt;/font&gt;&lt;/em&gt;).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{Pr}\left(x\right)&lt;/script&gt; is written in place of &lt;script type=&quot;math/tex&quot;&gt;\text{Pr}\left(X=x\right)&lt;/script&gt; for brevity. Read &lt;a href=&quot;#more&quot;&gt;more&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Term&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Common notations and more information (if any)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;estimation/prediction/inference of a quantity&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;the quantity with a “hat” eg. &lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\text{Pr}\left(y\left|x,\hat{\theta}\right.\right)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;ước lượng/dự đoán/suy diễn một đại lượng nào đấy&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;objective function, error function, loss function, cost function&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;J\left(\cdot\right)&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;L\left(\cdot\right)&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;l\left(\cdot\right)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;hàm mục tiêu, hàm lỗi, hàm tổn thất, hàm chi phí&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;learning, training; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;:  parameter estimation&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;học mô hình, huấn luyện mô hình, ước lượng tham số&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;evaluating, forward pass - &lt;font color=&quot;red&quot;&gt;as in&lt;/font&gt; “computing some quantity given estimates of all unknown quantities”&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;red&quot;&gt;note&lt;/font&gt;: not to be confused with &lt;code class=&quot;highlighter-rouge&quot;&gt;performance evaluation&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;tính toán, chiều xuôi&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;score function; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;: (inverse) link function&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;s\left(\cdot\right)&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;g\left(\cdot\right)&lt;/script&gt; if link function&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;hàm tính điểm, hàm liên kết&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;neuron/unit; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;: dimension (of a vector)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;x_{d}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is a dimesion of vector &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;nơ-ron, chiều (của một vec-tơ)&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;feature; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;: independent variable, explanatory variable, predictor&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;x_{d}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is a dimesion of vector &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. &lt;font color=&quot;red&quot;&gt;note&lt;/font&gt;: in practice, most of the time we imply &lt;code class=&quot;highlighter-rouge&quot;&gt;feature&lt;/code&gt; as &lt;code class=&quot;highlighter-rouge&quot;&gt;feature vector&lt;/code&gt;, thus use vector &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; instead&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;vec-tơ đặc trưng, biến độc lập, biến giải thích, nhân tố giải thích&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;mid-/high-level feature, hidden/latent variable; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;: hidden neuron&lt;strong&gt;s&lt;/strong&gt;/unit&lt;strong&gt;s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; if assumed a random variable&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;đặc trưng bậc trung hoặc bậc cao, biến ẩn, các nơ-ron ẩn&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;target, label; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;: dependent variable, response variable&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;mục tiêu, nhãn, biến phụ thuộc, biến (?)&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;observed data/variable(s),&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; if supervised learning&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;dữ liệu/biến quan sát được (đã biết)&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;unobserved data/variable(s)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\tilde{\mathcal{D}}&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;\tilde{\mathcal{x}}&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;x'&lt;/script&gt; ; or &lt;script type=&quot;math/tex&quot;&gt;x^{\left(\text{new}\right)}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;dữ liệu/biến không quan sát được (chưa biết)&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;data point&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; ; or (if working with more than 1 data point) &lt;script type=&quot;math/tex&quot;&gt;x^{\left(n\right)}&lt;/script&gt;, or &lt;script type=&quot;math/tex&quot;&gt;x_{n}&lt;/script&gt; if &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; represents a set of data points&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;điểm dữ liệu&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;parameter; &lt;font color=&quot;red&quot;&gt;related&lt;/font&gt;: weight, bias (as the “offset” from the origin)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; , &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; respectively&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;tham số, trọng số, độ lệch&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;red&quot;&gt;note&lt;/font&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;bias&lt;/code&gt; is an &lt;a href=&quot;//en.wikipedia.org/wiki/Umbrella_term&quot;&gt;umbrella term&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bias&lt;/code&gt; has more &lt;a href=&quot;//en.wikipedia.org/wiki/Bias_(statistics)&quot;&gt;common meanings&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;parameterized function&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;f\left(x,y\,\mathbf{;}\,\theta\right)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;hàm có tham số&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;parametric distribution&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;p\left(x\mathbf{;}\,\theta\right)&lt;/script&gt;; or &lt;script type=&quot;math/tex&quot;&gt;p_{\theta}\left(x\right)&lt;/script&gt; where &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; p\left(\cdot\right) &lt;/script&gt;&lt;/span&gt; is density function&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;em&gt;phân bố xác suất có tham số&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;more-notation&quot;&gt;&lt;a name=&quot;more&quot;&gt;More notation&lt;/a&gt;&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;For brevity, &lt;script type=&quot;math/tex&quot;&gt;\text{Pr}\left(x\right)&lt;/script&gt; is often seen in ML literature instead of &lt;script type=&quot;math/tex&quot;&gt;\text{Pr}\left(X=x\right)&lt;/script&gt; as in statistical texts. I also use an overhead circle e.g. &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \overset{\circ}{x} &lt;/script&gt;&lt;/span&gt; to denote random variable, in place of capital letters e.g. X, N, K which are preserved for either sets of data points, matrices, or total number of samples/classes/features/…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Notation&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \overset{\circ}{\mathbf{y}_{n}} &lt;/script&gt;&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;A random variable. Thus &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \text{Pr}\left(\overset{\circ}{y_{n}}|\cdot\right) &lt;/script&gt;&lt;/span&gt; implies a probability distribution.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; y_{n} &lt;/script&gt;&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;A realization of random variable &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \overset{\circ}{y_{n}} &lt;/script&gt;&lt;/span&gt;. Thus &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \text{Pr}\left(y_{n}|\cdot\right) &lt;/script&gt;&lt;/span&gt; is a value.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \Omega_{\overset{\circ}{y_{n}}} &lt;/script&gt;&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Set of all possible realization &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; y_{n}&lt;/script&gt;&lt;/span&gt;’s of random variable &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \overset{\circ}{y_{n}} &lt;/script&gt;&lt;/span&gt; i.e. &lt;strong&gt;&lt;em&gt;sample space&lt;/em&gt;&lt;/strong&gt; of &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \overset{\circ}{y_{n}} &lt;/script&gt;&lt;/span&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \hat{y}_{n} &lt;/script&gt;&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;An estimate of random variable &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \overset{\circ}{y_{n}} &lt;/script&gt;&lt;/span&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \underset{y_{n}^{'}}{\text{argmax}}\text{Pr}\left(y_{n}^{'}|\cdot\right) &lt;/script&gt;&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;short for &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \underset{y_{n}^{'}\in\Omega_{\overset{\circ}{y_{n}}}}{\text{argmax}}\text{Pr}\left(\overset{\circ}{y_{n}}=y_{n}^{'}|\cdot\right) &lt;/script&gt;&lt;/span&gt;. We use notation &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; y_{n}^{'} &lt;/script&gt;&lt;/span&gt; to not confuse with &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; y_{n} &lt;/script&gt;&lt;/span&gt; which is reserved for the realization provided by training data &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \mathcal{D}=\left\{ x_{n},y_{n}\right\}_{n=1}^{N}  &lt;/script&gt;&lt;/span&gt;.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;common-machine-learning-models-acronym&quot;&gt;&lt;a name=&quot;ml-models&quot;&gt;Common machine learning models acronym&lt;/a&gt;&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Acronym&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PGM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Probabilistic Graphical Models i.e. Probabilistic models&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GLM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Generalized Linear Models&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GMM, PPCA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(Gaussian) Mixture Models, Probabilistic Principle Component Analysis&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;HMM, LDS&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hidden Markov Models, Linear Dynamical Systems (for modelling &lt;em&gt;sequential data&lt;/em&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Topic Models&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Latent Dirichlet Allocation (LDA - &lt;em&gt;not to be confused with&lt;/em&gt; Linear Discriminant Analysis) and variants&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DNN&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Deep Neural Networks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MLP, CNN&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Multi-layer Perceptrons, Convolutional NNs i.e. FNN - Feed-forward NN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RNN&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Recurrent NNs, also including Recursive NN and Bi-directional RNN (for modelling &lt;em&gt;sequential data&lt;/em&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;EBM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Energy-based Models (&lt;em&gt;undirected&lt;/em&gt; PGM)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RBM, DBN, DBM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Restricted Boltzmann Machines, Deep Belief Networks (&lt;em&gt;not to be confused with&lt;/em&gt; Dynamic Bayesian Networks), Deep Boltzmann Machines&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;VAE, DRAW, AIR&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Variational Auto-encoder, Deep Recurrent Attentive Writer, Attention-Infer-Repeat&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GAN&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Generative Adversarial Networks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;AAE&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Adversarial Auto-encoders&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;SVM&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Support Vector Machines&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DP, GP&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Dirichlet Processes, Gaussian Processes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Tree, RF&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Decision Trees, Random Forests&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;kNN&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;k-Nearest Neighbours&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;back-propogation-algorithm&quot;&gt;Back-propogation algorithm&lt;/h2&gt;
&lt;p&gt;&lt;label for=&quot;backprop-demo&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;backprop-demo&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;em&gt;Conditions&lt;/em&gt;: (i) J is differentiable every where w.r.t. theta; (ii) J and all thetas form a directed acyclic computational graph. &lt;/span&gt; &lt;strong&gt;For what&lt;/strong&gt;: computes gradient &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; 
\nabla_{\theta}J=\dfrac{\partial J}{\partial\theta} &lt;/script&gt;&lt;/span&gt; for &lt;strong&gt;all&lt;/strong&gt; &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \theta 
&lt;/script&gt;&lt;/span&gt;’s of interest.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Use case(s)&lt;/em&gt;: update optimal parameter &lt;span&gt;​&lt;script type=&quot;math/tex&quot;&gt; \hat{\theta} &lt;/script&gt;&lt;/span&gt;’s of a neural network (or a certain class of probabilistic models) by gradient descent algorithms;&lt;/p&gt;

</description>
        <pubDate>Wed, 01 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://hoamle.github.io/post/17/machine-learning-appendix</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/17/machine-learning-appendix</guid>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>Computers can Draw (draft)</title>
        <description>&lt;p&gt;Survey on the attempts to build an AI artist&lt;/p&gt;

&lt;h2 id=&quot;history&quot;&gt;History&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;AARON (Harold Cohen)&lt;/li&gt;
  &lt;li&gt;“The Painting Fool” (Simon Colton)&lt;/li&gt;
  &lt;li&gt;“The Next Rembrandt” (TU Delft)&lt;/li&gt;
  &lt;li&gt;Machine learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;modern-advances&quot;&gt;Modern advances&lt;/h2&gt;

&lt;h3 id=&quot;non-photo-realistic-rendering-npr&quot;&gt;Non Photo-realistic Rendering (NPR)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;physic-based: NPR book&lt;/li&gt;
  &lt;li&gt;data-driven: texture/style transfer, e.g. Artomatix (Erric Risser et al), Neural Art (Gatys et al)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;generative-model-of-images&quot;&gt;Generative model of images&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Restricted Boltzman Machine (RBM)&lt;/li&gt;
  &lt;li&gt;Variational Auto Encoder (VAE), Deep Recurrent Attentive Writer (DRAW)&lt;/li&gt;
  &lt;li&gt;Generative Adversarial Network (GAN)&lt;/li&gt;
  &lt;li&gt;PixelRNN&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PPGN&lt;/strong&gt;: Generative net + conditioned + activation maximisation + prior structure = photo-realistic image generation!!
(inner-thought: 18-month ago this vague idea of “creative AI” drove me to machine/deep learning, and here we are!!)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;applications-in-graphics&quot;&gt;Applications in graphics&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;iGAN (Jun-Yan Zhu et al)&lt;/li&gt;
  &lt;li&gt;StyLit (Jakub Fišer et al)&lt;/li&gt;
  &lt;li&gt;Colorisation (various) (note-to-self: &lt;code class=&quot;highlighter-rouge&quot;&gt;r/colorization&lt;/code&gt; might be a good place to crawl labelled data)&lt;/li&gt;
  &lt;li&gt;Texture propagation (Satoshi Iizuaka et al)&lt;/li&gt;
  &lt;li&gt;Sketch cleaning (Satoshi Iizuaka et al)&lt;/li&gt;
  &lt;li&gt;Super-resolution&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 01 Jan 2017 00:00:00 -0500</pubDate>
        <link>http://hoamle.github.io/post/17/computers-can-draw</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/17/computers-can-draw</guid>
        
        <category>arts</category>
        
        <category>tech</category>
        
        <category>AI</category>
        
        
      </item>
    
      <item>
        <title>A self-study map of modern Machine learning</title>
        <description>&lt;p&gt;The map&lt;label for=&quot;sn-id-plan&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-plan&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;Motivated by &lt;a href=&quot;//metacademy.org/about&quot;&gt;metacademy's philosophy&lt;/a&gt; &lt;/span&gt; below is one of many possible projections of the field Machine Learning, with focus on Deep learning and Bayesian modelling.&lt;/p&gt;

&lt;p&gt;This map focuses on &lt;strong&gt;model classes&lt;/strong&gt; &amp;amp; connection to other fields of study. In addition, the map also aims to devise a &lt;em&gt;more principled&lt;/em&gt; &lt;a href=&quot;#plan&quot;&gt;&lt;strong&gt;study-plan&lt;/strong&gt;&lt;/a&gt; to make it easier for aspiring ML self-learners to step-up/transit from &lt;a href=&quot;//www.coursera.org/learn/machine-learning&quot;&gt;basic ML&lt;/a&gt; or DNN to PGM, &lt;em&gt;given that they had covered the &lt;a href=&quot;/post/17/mlpp-primer&quot;&gt;&lt;strong&gt;“Base” course&lt;/strong&gt;&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;em&gt;Disclaimer&lt;/em&gt;&lt;/strong&gt;: The map was designed accordingly to my self-study/reading/working via MOOCs/papers/projects related to statistical machine learning, thus there might exist some (hopefully minor) inaccuracies. Any suggestions and critics to improve this map are highly appreciated.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;label for=&quot;map-note&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;map-note&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;“Gates” in the figure refers to “gating mechanism” presented in LSTM / GRU modules. See &lt;a href=&quot;/post/17/machine-learning-appendix#ml-models&quot;&gt;&lt;strong&gt;ML Appendix&lt;/strong&gt;&lt;/a&gt; for description of the other acronyms. For a more comprehensive picture/maps of model classes, see &lt;a href=&quot;//videolectures.net/deeplearning2016_mohamed_generative_models/&quot;&gt;&lt;strong&gt;Shakir Mohamed's talk&lt;/strong&gt;&lt;/a&gt;. &lt;/span&gt;
&lt;!-- &lt;figure&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;img src='/assets/img/mapofML.png'/&gt;&lt;/figure&gt; --&gt;
&lt;a href=&quot;/assets/img/mapofML.png&quot; style=&quot;border-bottom: unset&quot; name=&quot;map&quot;&gt;&lt;img src=&quot;/assets/img/mapofML.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a name=&quot;plan&quot;&gt;&lt;strong&gt;study-plan&lt;/strong&gt;&lt;/a&gt; can be read directly from the model classes i.e. the nodes in the map. The expected contents&lt;label for=&quot;project&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;project&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: From my experience, working on non-trivial research / practical &lt;em&gt;projects&lt;/em&gt; with a well-defined topic and scope helps cover a lot of materials while making the theory less daunting. It is &lt;em&gt;provided&lt;/em&gt; that you have the &lt;strong&gt;&lt;em&gt;minimum foundation on the prerequisites&lt;/em&gt;&lt;/strong&gt; though, which varies depending on the projects.
 &lt;/span&gt; covered in each node is summarized in the list below, in which the references are chosen so that their technical details have as small overlap with the references in other nodes as possible. The objective is to optimize the time spent on learning, while covering wide enough spectrum of ML research. Also, the further downn we go on the map, the more advanced materials in &lt;em&gt;Global topics&lt;/em&gt; we will cover.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;em&gt;Disclaimer&lt;/em&gt;&lt;/strong&gt;. The following references are subject to my current expertise (which obviously has lots of room to improve). Any suggestions for better alternatives &lt;em&gt;and&lt;/em&gt; for missing nodes in the study-plan are welcome. Also, &lt;a href=&quot;//metacademy.org/&quot;&gt;metacademy&lt;/a&gt; is an excellent source to look for (in-depth) references if you want to learn about a new ML concept.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;base : as &lt;a href=&quot;#ilo&quot;&gt;Intended Learning Objectives&lt;/a&gt; above
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: &lt;a href=&quot;#note&quot;&gt;base-notes&lt;/a&gt;, &lt;a href=&quot;#ref&quot;&gt;base-ref&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;pgm&quot;&gt;PGM&lt;/a&gt; (all stochastic nodes&lt;label for=&quot;sn-id-node&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-node&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Nodes of the respective &lt;a href=&quot;#graphical&quot;&gt;&lt;em&gt;graphical model&lt;/em&gt;&lt;/a&gt;, not the study-plan &lt;/span&gt;) : Intro. to Latent Variable Models + Bayesian inference methods (&lt;em&gt;Variational methods&lt;/em&gt;, &lt;em&gt;MCMC sampling e.g. Gibbs sampling&lt;/em&gt;) + Sparse regularization + (optional) convex optimization
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: as in “base” course’s &lt;a href=&quot;#note&quot;&gt;Recap&lt;/a&gt; slides, optionally incl. HMM, LDS for modelling &lt;em&gt;sequential data&lt;/em&gt;. Further reading: &lt;a href=&quot;//www.coursera.org/specializations/probabilistic-graphical-models&quot;&gt;Daphne Koller’s course&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;dnn&quot;&gt;DNN&lt;/a&gt; (all deterministic nodes&lt;label for=&quot;sn-id-node&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-node&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Nodes of the respective &lt;a href=&quot;#graphical&quot;&gt;&lt;em&gt;graphical model&lt;/em&gt;&lt;/a&gt;, not the study-plan &lt;/span&gt;) : “Architectures” + Applications of modern DNNs to CompVis, NLP + Attention mechanism + (optional) non-convex optimization
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: &lt;a href=&quot;//cs231n.stanford.edu/&quot;&gt;CS231n&lt;/a&gt;, &lt;a href=&quot;//cs224d.stanford.edu/&quot;&gt;CS224d&lt;/a&gt;. Further reading: &lt;a href=&quot;//www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu&quot;&gt;Nando de Freitas’s course&lt;/a&gt; @ Oxford,  &lt;a href=&quot;//www.deeplearningbook.org/&quot;&gt;Deep Learning textbook&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;“Deep” PGM : &lt;a name=&quot;ebm&quot;&gt;Undirected PGM&lt;/a&gt; + More MCMC sampling methods (&lt;em&gt;e.g. CD-k&lt;/em&gt;)
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: TODO - &lt;a href=&quot;//www.coursera.org/specializations/probabilistic-graphical-models&quot;&gt;Daphne Koller’s course&lt;/a&gt; (undirected PGM lectures), last-half of &lt;a href=&quot;//www.coursera.org/learn/neural-networks&quot;&gt;Geoffrey Hinton’s NN course&lt;/a&gt;, and/or &lt;a href=&quot;//www.cs.cmu.edu/~rsalakhu/&quot;&gt;Ruslan Salakhutdinov’s tutorials&lt;/a&gt; in KDD 2011/2014 (?)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;pgmdnn&quot;&gt;PGM+DNN&lt;/a&gt; : PGM whose stochastic nodes are parametrized by DNNs + Monte Carlo’s SGD-based Variational Inference + Structured priors i.e. Structured latent factors (incl. probabilistic attention mechanism)
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: &lt;a href=&quot;//videolectures.net/deeplearning2016_mohamed_generative_models/&quot;&gt;Shakir Mohamed’s talk&lt;/a&gt; for the big picture + (huge body of) relevant works, especially VAE and variants.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;gan&quot;&gt;GAN&lt;/a&gt; : Adversarial learning + Optimize (minimax.) an objective function and related issues (&lt;em&gt;e.g. mode collapsing&lt;/em&gt;) + Insight to Game Theory research (?)
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: TODO - Ian Goodfellow et al’s original paper (obviously) + an up-to-date GAN survey (?)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;[TODO - other topics not mentioned]
    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;refs&lt;/em&gt;: distribute materials in pending reading lists to appropriate nodes
&lt;a href=&quot;//metacademy.org/roadmaps/rgrosse/bayesian_machine_learning&quot;&gt;Metacademy’s Bayesian ML roadmap&lt;/a&gt;
&lt;a href=&quot;//truyentran.github.io/ausdm16-tute.html&quot;&gt;Dr Truyen Tran’s 3-part tutorial @ AusDM’16 + Exhaustive list of resources&lt;/a&gt;
Ferenc Huszar’s posts, e.g. &lt;a href=&quot;//www.inference.vc/deep-learning-is-easy/&quot;&gt;Deep Learning is easy&lt;/a&gt;; &lt;a href=&quot;//www.inference.vc/probabilistic-models-and-autoencoders-my-new-favourite-papers/&quot;&gt;probabilistic interpretation of DAE&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;[TODO - …]&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 01 Oct 2016 00:00:00 -0400</pubDate>
        <link>http://hoamle.github.io/post/16/a-ml-dl-map</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/16/a-ml-dl-map</guid>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>Deep Art fun</title>
        <description>&lt;p&gt;Last weekend I finally had the time to take some of personal photos and &lt;em&gt;&quot;paint&quot;&lt;/em&gt; them in Van Gogh and other artist styles. The &quot;painting&quot; part was actually done automatically by &lt;a href=&quot;#deepart&quot;&gt;&lt;strong&gt;DeepArt algorithm&lt;/strong&gt;&lt;/a&gt;&lt;label for=&quot;sn-id-artomatix&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-artomatix&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;It’s worth to note that &lt;a href=&quot;//artomatix.com/&quot;&gt;Artomatix&lt;/a&gt; - an Irish startup - had introduced a &lt;a href=&quot;//youtu.be/un9lSayNOIY?t=51&quot;&gt;similar work&lt;/a&gt; under the name “Texture Painting” several months before DeepArt algorithm was published. &lt;/span&gt; - an inspiring application from Deep learning research. In short, the algorithm takes your source photo - hereby referred as &lt;strong&gt;&lt;em&gt;content-image&lt;/em&gt;&lt;/strong&gt; - and a reference style - called &lt;strong&gt;&lt;em&gt;style-image&lt;/em&gt;&lt;/strong&gt; - as the inputs and produces your source photo in that style.&lt;/p&gt;

&lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt;
&lt;p&gt;I used &lt;a href=&quot;//github.com/jcjohnson/neural-style&quot;&gt;jcjohnson’s implementation&lt;/a&gt; of DeepArt algorithm for this demo.&lt;/p&gt;

&lt;p&gt;Here we have the content-image on the top-left, the style-image is an artwork by artist Leonid Afremov on the top-right, and the photo generated in Afremov's style at the bottom.&lt;/p&gt;

&lt;div class=&quot;img_row&quot; style=&quot;width: unset; height: 200px; padding: unset; margin: unset&quot;&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/content-imgs/exeter.jpg&quot; /&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/style-imgs/Afremov2.jpg&quot; /&gt;
    
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/visually-appealing/exeter-afremov2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The machine did not “paint” the picture out of the blue, it's an iterative process. In short, it starts with a blank (noisy) canvas and tries to learn prominent features in both content-image and style-image(s) and present them on the final product. That learning process is mathematically expressed as optimization process of a function representing the combined &lt;em&gt;similarity&lt;/em&gt; between the output and the inputs. Optimizing such function requires an algorithm which goes through series of iterative update, visualized as followed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/exeter_afremov2.gif&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;more-images&quot;&gt;More images&lt;/h2&gt;
&lt;p&gt;&lt;label for=&quot;mn-hardware&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mn-hardware&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;em&gt;Technical bit:&lt;/em&gt; Images were produced by NIN model + Adam optimization. If hardware constrainst is not a problem, visual results should be &lt;em&gt;considerably &lt;strong&gt;improved&lt;/strong&gt;&lt;/em&gt;  by using VGG-19 model + L-BFGS optimization. &lt;/span&gt;
&lt;strong&gt;Note:&lt;/strong&gt; Due to hardware constrainst, most of images below were generated from &lt;em&gt;poor-man&lt;/em&gt; configs, thus did not yield the best possible quality. I will be sporadically updating results in near future.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Style image&lt;/strong&gt;: by &lt;a href=&quot;//www.behance.net/gallery/13033419/Selected-Artworks-2013-Oil-Acrylic-Watercolor&quot;&gt;@creativemints&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;img_row&quot; style=&quot;width: unset; height: 200px; padding: unset; margin: unset&quot;&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/content-imgs/potr.jpg&quot; /&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/style-imgs/lostquilt_at_pinterest.jpg&quot; /&gt;
    
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/lostquilt.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Style image&lt;/strong&gt;: by Leonid Afremov&lt;/p&gt;
&lt;div class=&quot;img_row&quot; style=&quot;width: unset; height: 200px; padding: unset; margin: unset&quot;&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/content-imgs/pedals.jpg&quot; /&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/style-imgs/Afremov4.jpg&quot; /&gt;
    
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/visually-appealing/pedals-afremov4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Style image&lt;/strong&gt;: Van Gogh's Starry Night&lt;/p&gt;
&lt;div class=&quot;img_row&quot; style=&quot;width: unset; height: 200px; padding: unset; margin: unset&quot;&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/content-imgs/exe_quay.jpg&quot; /&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/style-imgs/starry_night.jpg&quot; /&gt;
    
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/visually-appealing/exe_quay-starrynight.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Style image&lt;/strong&gt;: Van Gogh's Wheat Field with Crows&lt;/p&gt;
&lt;div class=&quot;img_row&quot; style=&quot;width: unset; height: 200px; padding: unset; margin: unset&quot;&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/content-imgs/camb.jpg&quot; /&gt;
    &lt;img class=&quot;col&quot; style=&quot;width: 50%&quot; src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/style-imgs/vangogh_Wheat_Field_with_Crows.jpg&quot; /&gt;
    
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;//raw.githubusercontent.com/hoamle/neural-style-example/master/visually-appealing/camb-vangogh_wheatfield.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;observation&quot;&gt;Observation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Size matters&lt;/strong&gt;. The higher the output image resolution, the more details in the content-image can be explicitly expressed by the indicated style. However, memory is a &lt;em&gt;big&lt;/em&gt; trade-off. Default output image size (max. 512px-wide) on an NIN took as small as 5-600MB, but a 784px image devours 3 times as much!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For visual appeal&lt;/strong&gt;, an &lt;strong&gt;expressive&lt;/strong&gt; style and/or &lt;strong&gt;resemblance&lt;/strong&gt; between content-style image pair is the key:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;&quot;Expressive&quot;&lt;/em&gt; in this context is about texture i.e. discernible patterns in colors, strokes, blobs. Example work: Leonid Afremov's painting, The Scream, Monet's water lilies,… Experimentation with realism pieces by the old masters, e.g. Jean Leon Gerome, as style-images usually yields unsatisfiying results.&lt;/li&gt;
  &lt;li&gt;Although not always, content- and style-images of similar semantics pair well with each other. For example, a landscape picture should play along well with Starry Night or Wheat Field and the Crows; a portrait and one of Picasso's self-portraits also make a nice combination.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Last but not least, me drooling over a Titan X with gigantic memory&lt;/p&gt;

&lt;h2 id=&quot;hardware-setup&quot;&gt;Hardware setup&lt;/h2&gt;
&lt;p&gt;The main work-horse is a humble 2GB nVidia GTX 660 GPU&lt;label for=&quot;sn-gpu&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-gpu&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;i.e. common video graphic card for gaming &lt;/span&gt; plugged in a dated LGA 775 desktop. &lt;del&gt;Each image was generated in ~90 seconds (for a 512px-image) or 2-3 mins (for a 784px-image)&lt;/del&gt;&lt;label for=&quot;sn-id-advances&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-advances&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;em&gt;Learning-based approaches&lt;/em&gt; e.g. &lt;a href=&quot;//github.com/jcjohnson/fast-neural-style&quot;&gt;fast-neural-style&lt;/a&gt; have largely reduce generation time down to just &lt;em&gt;a few seconds&lt;/em&gt; &lt;/span&gt;. GPU(s) with generous memory is desirable.&lt;/p&gt;

&lt;p&gt;It's &lt;em&gt;much&lt;/em&gt; faster to run DeepArt algorithm on GPU(s) instead of common CPUs. Even a modern i7 K-series can take upto hour to train and generate 1 image of above sizes. However, running on CPU can take advantages of &lt;em&gt;abundant&lt;/em&gt; host memory (easily &amp;gt;8GB on a single machine), not to mention the possibility to be accompanied with a coprocessor (eg: Xeon Phi), or running on distributed platform.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;&lt;a name=&quot;refs&quot;&gt;References&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;deepart&quot;&gt;&lt;a href=&quot;//arxiv.org/abs/1508.06576&quot;&gt;A Neural Algorithm of Artistic Style&lt;/a&gt; (Gatys et al, 2015) i.e. DeepArt algorithm. The name “DeepArt” is adopted from the authors’ commercial website &lt;a href=&quot;//deepart.io/&quot;&gt;deepart.io&lt;/a&gt;
&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sat, 16 Jan 2016 00:00:00 -0500</pubDate>
        <link>http://hoamle.github.io/post/16/deep-art-fun</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/16/deep-art-fun</guid>
        
        <category>arts</category>
        
        <category>AI</category>
        
        <category>general-audience</category>
        
        
      </item>
    
      <item>
        <title>Toolbar-Creator layout for Photoshop and ClipStudio Paint</title>
        <description>&lt;p&gt;&lt;img class=&quot;col banner&quot; src=&quot;//i.imgur.com/Z8ivi4l.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Toolbar Creator&lt;/strong&gt; is one of few especially useful on-screen toolbars for Windows Tablet PCs. It makes using Windows tablets without keyboard much more comfortable and convenient. The software is developed by &lt;a href=&quot;//forum.tabletpcreview.com/threads/toolbar-creator-v-2-2-beta-available-for-download.63014/&quot;&gt;&lt;strong&gt;lblb&lt;/strong&gt;&lt;/a&gt; at TabletPC Review forum, which is a user-friendly interface for &lt;code class=&quot;highlighter-rouge&quot;&gt;RawInputControlTest&lt;/code&gt; script by &lt;a href=&quot;//39kasen.sakura.ne.jp/rawinputcontroltest/&quot;&gt;&lt;strong&gt;koide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This repository is a toolbar &lt;em&gt;layout&lt;/em&gt;, specifically designed for painting in Adobe (R) Photoshop (R) and ClipStudio Paint aka. Manga Studio (R). Icon design is kindly provided by &lt;a href=&quot;//forum.tabletpcreview.com/threads/slatepal-dock-developing.54774/&quot;&gt;&lt;strong&gt;gahfe&lt;/strong&gt;&lt;/a&gt; at TabletPC Review forum. The layout was created, &lt;strong&gt;&lt;em&gt;assuming&lt;/em&gt;&lt;/strong&gt; that modifier keys (Ctrl, Alt, Shift) are accessible from hardware buttons. I have the keys mapped to buttons on a Zeemote controller, while the controller &lt;a href=&quot;//i.imgur.com/Z8ivi4l.jpg&quot;&gt;is attached on the side of the tablet&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;screenshot&quot;&gt;Screenshot&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;//raw.githubusercontent.com/hoamle/Toolbar-Creator/master/v2_2_b5/v2_2_b5.png&quot; alt=&quot;Screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;p&gt;Tested with Toolbar Creator v2.2 beta 5&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Download, extract this &lt;a href=&quot;//github.com/hoamle/Toolbar-Creator/archive/master.zip&quot;&gt;GitHub repo&lt;/a&gt;, and go to &lt;code class=&quot;highlighter-rouge&quot;&gt;Toolbar-Creator-master&lt;/code&gt; directory.&lt;/li&gt;
  &lt;li&gt;Copy and paste directory &lt;code class=&quot;highlighter-rouge&quot;&gt;[version]\Files&lt;/code&gt; into your &lt;code class=&quot;highlighter-rouge&quot;&gt;Toolbar Creator&lt;/code&gt;’s root directory. Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;[version]&lt;/code&gt; with either &lt;code class=&quot;highlighter-rouge&quot;&gt;v2_1&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;v2_2_b5&lt;/code&gt; accordingly to your existing &lt;code class=&quot;highlighter-rouge&quot;&gt;Toolbar Creator&lt;/code&gt; version.&lt;/li&gt;
  &lt;li&gt;Replace/Merge all existing files/folders if prompted.&lt;/li&gt;
  &lt;li&gt;Launch Toolbar Creator and change the current toolbar to &lt;code class=&quot;highlighter-rouge&quot;&gt;painting&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 31 Oct 2014 00:00:00 -0400</pubDate>
        <link>http://hoamle.github.io/post/14/toolbar-creator-layout-clipstudio-paint</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/14/toolbar-creator-layout-clipstudio-paint</guid>
        
        <category>tech</category>
        
        <category>arts</category>
        
        
      </item>
    
      <item>
        <title>Hello World</title>
        <description>&lt;p&gt;Hello world for the &lt;script type=&quot;math/tex&quot;&gt;n+1&lt;/script&gt; times. This post will serve as a repo for troubleshooting blogging problems.&lt;/p&gt;

&lt;h3 id=&quot;convert-between-different-sources&quot;&gt;Convert between different sources&lt;/h3&gt;
&lt;p&gt;HTML to MarkDown: &lt;code class=&quot;highlighter-rouge&quot;&gt;pandoc input.html -o output.md --parse-raw&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;markdown-editors&quot;&gt;Markdown editors&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;//github.com/SublimeText-Markdown/MarkdownEditing&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MarkdownEditting&lt;/code&gt;&lt;/a&gt; for Sublime Text&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;knitr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Warning: package 'knitr' was built under R version 3.3.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;123&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Does &lt;strong&gt;knitr&lt;/strong&gt; work with Python? Use the chunk option &lt;code class=&quot;highlighter-rouge&quot;&gt;engine='python'&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'hello, python world!'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## hello, python world!
## ['hello,', 'python', 'world!']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;{% highlight c++ %}  &lt;br /&gt; code code code &lt;br /&gt; {% endhighlight %}&lt;/p&gt;

&lt;p&gt;Produces something like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input a string: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;getline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
	
	&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;charArray&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;charArray&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;charArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Mon, 08 Sep 2014 00:00:00 -0400</pubDate>
        <link>http://hoamle.github.io/post/14/hello-world</link>
        <guid isPermaLink="true">http://hoamle.github.io/post/14/hello-world</guid>
        
        
      </item>
    
  </channel>
</rss>
